{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import metrics.geodist_metric as geodist_metric\n",
    "from utils.shape_util import compute_geodesic_distmat\n",
    "import torch\n",
    "\n",
    "\n",
    "dataset_name = 'SMAL_nocat_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")\n",
    "\n",
    "dist_mat_list = []\n",
    "\n",
    "for i in tqdm(range(len(single_dataset))):\n",
    "\n",
    "    data_i = single_dataset[i]\n",
    "\n",
    "    dist_mat = torch.tensor(\n",
    "        compute_geodesic_distmat(data_i['verts'].numpy(), data_i['faces'].numpy())    \n",
    "    )\n",
    "    \n",
    "    dist_mat_list.append(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for file in single_dataset.off_files:\n",
    "    categories.append(\n",
    "        (file.split('/')[-1]).split('_')[0]\n",
    "        )\n",
    "    \n",
    "categories = list(set(categories))\n",
    "\n",
    "print(categories)\n",
    "\n",
    "err_by_category = {category: 0 for category in categories}\n",
    "times_by_category = {category: 0 for category in categories}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = f'/home/s94zalek_hpc/baselines/Spatially-and-Spectrally-Consistent-Deep-Functional-Maps/data/results/SMAL_iso/p2p_21'\n",
    "\n",
    "geo_err_list = []\n",
    "\n",
    "for i in tqdm(range(len(pair_dataset))):\n",
    "    \n",
    "    data_i = pair_dataset[i]\n",
    "    \n",
    "    first_idx = data_i['first']['id']\n",
    "    second_idx = data_i['second']['id']\n",
    "    \n",
    "    # print(first_idx, second_idx)\n",
    "    \n",
    "    off_first = single_dataset.off_files[first_idx]\n",
    "    name_first = off_first.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    off_second = single_dataset.off_files[second_idx]\n",
    "    name_second = off_second.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # print(name_first, name_second)\n",
    "    \n",
    "    # break    \n",
    "    \n",
    "    \n",
    "    p2p = torch.tensor(\n",
    "        np.loadtxt(f'{path}/{name_first}_{name_second}.txt')\n",
    "    ).int()\n",
    "    \n",
    "    dist_x = dist_mat_list[first_idx]\n",
    "    dist_y = dist_mat_list[second_idx]\n",
    "    \n",
    "    corr_first = data_i['first']['corr']\n",
    "    corr_second = data_i['second']['corr']\n",
    "    \n",
    "    geo_err = geodist_metric.calculate_geodesic_error(\n",
    "        dist_x, corr_first.cpu(), corr_second.cpu(), p2p, return_mean=True\n",
    "    ) * 100\n",
    "    geo_err_list.append(geo_err)\n",
    "\n",
    "\n",
    "    category_first = (single_dataset.off_files[int(first_idx)].split('/')[-1]).split('_')[0]\n",
    "    category_second = (single_dataset.off_files[int(second_idx)].split('/')[-1]).split('_')[0]\n",
    "            \n",
    "            # if 'hippo' in category_first or 'hippo' in category_second:\n",
    "            #     continue\n",
    "            \n",
    "    err_by_category[category_first] += float(geo_err)\n",
    "    err_by_category[category_second] += float(geo_err)\n",
    "    \n",
    "    times_by_category[category_first] += 1\n",
    "    times_by_category[category_second] += 1\n",
    "            \n",
    "\n",
    "    \n",
    "geo_err_list = torch.tensor(geo_err_list)\n",
    "print(f'{dataset_name}, mean geo err: {geo_err_list.mean()}, median: {geo_err_list.median()}')\n",
    "\n",
    "for category in categories:\n",
    "    err_by_category[category] /= times_by_category[category] if times_by_category[category] > 0 else 1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_by_category_list = sorted(\n",
    "    [(k, v) for k, v in err_by_category.items()],\n",
    "    key=lambda x: x[1], reverse=False\n",
    ")\n",
    "categories_sorted = [entry[0] for entry in err_by_category_list]\n",
    "\n",
    "for category in categories_sorted:\n",
    "    print(f'{category}: {err_by_category[category]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
