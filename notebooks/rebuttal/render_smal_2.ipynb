{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "import trimesh\n",
    "import my_code.diffusion_training_sign_corr.data_loading as data_loading\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh.scene\n",
    "import trimesh.scene.lighting\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def interpolate_colors(values, cmap, dtype=np.uint8):\n",
    "    # make input always float\n",
    "    values = np.asanyarray(values, dtype=np.float64).ravel()\n",
    "    # scale values to 0.0 - 1.0 and get colors\n",
    "    colors = cmap((values - values.min()) / values.ptp())\n",
    "    # convert to 0-255 RGBA\n",
    "    rgba = trimesh.visual.color.to_rgba(colors, dtype=dtype)\n",
    "    \n",
    "    return rgba\n",
    "\n",
    "    # mesh2.apply_transform(trimesh.transformations.rotation_matrix(np.pi/8, [1, 0, 0], [0, 0, 0]))\n",
    "    \n",
    "    # trimesh.smoothing.filter_taubin(mesh1, iterations=3)\n",
    "    # trimesh.smoothing.filter_taubin(mesh2, iterations=3)\n",
    "    \n",
    "    # scene.add_geometry(mesh1)\n",
    "    # scene.add_geometry(mesh2)\n",
    "    \n",
    "    # scene.add_geometry(trimesh.creation.axis(origin_size=0.05))\n",
    "\n",
    "    # return scene\n",
    "    \n",
    "    \n",
    "def get_cmap():\n",
    "    SAMPLES = 100\n",
    "    ice = px.colors.sample_colorscale(\n",
    "        \n",
    "        # DT4D\n",
    "        # px.colors.cyclical.Edge,\n",
    "        \n",
    "        # FAUST\n",
    "        px.colors.sequential.Jet,\n",
    "        \n",
    "        \n",
    "        \n",
    "        # SHREC19\n",
    "        # px.colors.diverging.Picnic,\n",
    "        \n",
    "        # SCAPE\n",
    "        # px.colors.cyclical.HSV,\n",
    "        \n",
    "        # px.colors.cyclical.IceFire,\n",
    "        \n",
    "        \n",
    "        # px.colors.sequential.Blackbody,\n",
    "        # px.colors.sequential.Viridis,\n",
    "        SAMPLES)\n",
    "    rgb = [px.colors.unconvert_from_RGB_255(px.colors.unlabel_rgb(c)) for c in ice]\n",
    "\n",
    "    # rgb = rgb[::-1]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(rgb, name='Ice', N=SAMPLES)\n",
    "\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def render_mesh(scene, mesh, path):\n",
    "    \n",
    "    scene.geometry.clear()\n",
    "    scene.add_geometry(mesh)\n",
    "    \n",
    "    scene.set_camera()\n",
    "    \n",
    "    proportion = (mesh.vertices[:, 0].max() - mesh.vertices[:, 0].min()) / (mesh.vertices[:, 1].max() - mesh.vertices[:, 1].min())\n",
    "    # proportion=1\n",
    "        \n",
    "    # png = scene.save_image(resolution=(int(proportion*1080), 1080), visible=True)\n",
    "\n",
    "\n",
    "    with pyvirtualdisplay.Display(visible=False, size=(1920, 1080)) as disp:\n",
    "        png = scene.save_image(resolution=(int(proportion*1080), 1080), visible=True)\n",
    "\n",
    "    # png = scene.save_image(resolution=(int(proportion*1080), 1080), visible=True)\n",
    "\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(png)\n",
    "\n",
    "    return png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "scene = trimesh.Scene()\n",
    "\n",
    "dataset_name = 'SMAL_nocat_pair'\n",
    "\n",
    "single_dataset, pair_dataset = data_loading.get_val_dataset(\n",
    "    dataset_name, 'test', 128, preload=False, return_evecs=True, centering='bbox'\n",
    ")\n",
    "\n",
    "\n",
    "if dataset_name == 'SHREC19_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SHREC19_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_intra_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_intra_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'DT4D_inter_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_template_remeshed/eval/checkpoint_99.pt/DT4D_inter_pair-test/no_smoothing/2024-11-10_21-20-05/pairwise_results.json'\n",
    "elif dataset_name == 'FAUST_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/FAUST_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SCAPE_r_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_1-2ev_64-128-128_remeshed_fixed/eval/epoch_99/SCAPE_r_pair-test/no_smoothing/2024-11-04_22-27-59/pairwise_results.json'\n",
    "elif dataset_name == 'SMAL_nocat_pair':\n",
    "    file_name = '/lustre/mlnvme/data/s94zalek_hpc-shape_matching/ddpm_checkpoints/single_64_SMAL_nocat_64_SMAL_isoRemesh_0.2_0.8_nocat_1-2ev_64k/eval/epoch_99/SMAL_nocat_pair-test/no_smoothing/2025-01-24_16-01-31/pairwise_results.json'\n",
    "        \n",
    "with open(file_name, 'r') as f:\n",
    "    p2p_saved = json.load(f)\n",
    "\n",
    "\n",
    "geo_err_list = torch.tensor([p2p_saved[i]['geo_err_median_pairzo'] for i in range(len(p2p_saved))])\n",
    "idxs_geo_err = torch.argsort(geo_err_list, descending=True)\n",
    "\n",
    "\n",
    "base_path = f'/lustre/mlnvme/data/s94zalek_hpc-shape_matching/figures/p2p/{dataset_name}'\n",
    "\n",
    "# if os.path.exists(base_path):\n",
    "#     os.system(f'rm -r {base_path}')\n",
    "\n",
    "os.makedirs(f\"{base_path}/single\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/combined\", exist_ok=True)\n",
    "\n",
    "cmap = get_cmap()\n",
    "\n",
    "random_order = torch.randperm(len(idxs_geo_err))[:200]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_colored_meshes(verts_x, faces_x, verts_y, faces_y, p2p, dataset_name, axes_color_gradient=[0, 1],\n",
    "                 base_cmap='jet'):\n",
    "    \n",
    "    # assert axes_color_gradient is a list or tuple\n",
    "    assert isinstance(axes_color_gradient, (list, tuple)), \"axes_color_gradient must be a list or tuple\"\n",
    "    assert verts_y.shape[0] == len(p2p), f\"verts_y {verts_y.shape} and p2p {p2p.shape} must have the same length\"\n",
    "\n",
    "    if 'SMAL' in dataset_name:\n",
    "\n",
    "        verts_x_cloned = verts_x.clone()\n",
    "        \n",
    "        verts_x[:, 0] = verts_x_cloned[:, 2]\n",
    "        verts_x[:, 1] = -verts_x_cloned[:, 1]\n",
    "        verts_x[:, 2] = verts_x_cloned[:, 0]\n",
    "        \n",
    "        verts_y_cloned = verts_y.clone()\n",
    "        \n",
    "        verts_y[:, 0] = verts_y_cloned[:, 2]\n",
    "        verts_y[:, 1] = -verts_y_cloned[:, 1]\n",
    "        verts_y[:, 2] = verts_y_cloned[:, 0]\n",
    "        \n",
    "       \n",
    "    ################################################## \n",
    "    # rotate to coordinate axes\n",
    "    ##################################################\n",
    "    \n",
    "    mesh1 = trimesh.Trimesh(vertices=verts_x, faces=faces_x, process=False, validate=False)\n",
    "    mesh2 = trimesh.Trimesh(vertices=verts_y, faces=faces_y, process=False, validate=False)\n",
    "    \n",
    "    # indx = 38\n",
    "    # mesh1.apply_transform(trimesh.transformations.rotation_matrix(3*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    # mesh2.apply_transform(trimesh.transformations.rotation_matrix(-2*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    \n",
    "    # indx = 86\n",
    "    # mesh2.apply_transform(trimesh.transformations.rotation_matrix(-2.5*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    # mesh1.apply_transform(trimesh.transformations.rotation_matrix(3.0*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    # mesh1.apply_transform(trimesh.transformations.rotation_matrix(-0.5*np.pi/8, [1, 0, 0], [0, 0, 0]))\n",
    "    \n",
    "    # indx = 279\n",
    "    mesh1.apply_transform(trimesh.transformations.rotation_matrix(6*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    mesh2.apply_transform(trimesh.transformations.rotation_matrix(-0.8*np.pi/8, [0, 1, 0], [0, 0, 0]))\n",
    "    mesh2.apply_transform(trimesh.transformations.rotation_matrix(-0.4*np.pi/8, [0, 0, 1], [0, 0, 0]))\n",
    "    # mesh2.apply_transform(trimesh.transformations.rotation_matrix(-0.5*np.pi/8, [0, 0, 0], [0, 0, 0]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # mesh2.apply_transform(trimesh.transformations.rotation_matrix(0.3*np.pi/8, [0, 0, 1], [0, 0, 0]))\n",
    "    \n",
    "    mesh1.apply_transform(trimesh.transformations.reflection_matrix((0, 0, 0), (1, 0, 0)))\n",
    "    mesh2.apply_transform(trimesh.transformations.reflection_matrix((0, 0, 0), (1, 0, 0)))\n",
    "    \n",
    "    # trimesh.repair.fix_inversion(mesh1)\n",
    "    \n",
    "    verts_x = torch.tensor(mesh1.vertices, dtype=torch.float32)\n",
    "    verts_y = torch.tensor(mesh2.vertices, dtype=torch.float32)\n",
    "        \n",
    "    ##################################################\n",
    "    # color gradient\n",
    "    ##################################################\n",
    "    \n",
    "    coords_x_norm = torch.zeros_like(verts_x)\n",
    "    for i in range(3):\n",
    "        coords_x_norm[:, i] = (verts_x[:, i] - verts_x[:, i].min()) / (verts_x[:, i].max() - verts_x[:, i].min())\n",
    "\n",
    "    coords_interpolated = torch.zeros(verts_x.shape[0])\n",
    "    for i in axes_color_gradient:\n",
    "        coords_interpolated += coords_x_norm[:, i]\n",
    "        \n",
    "    # coords_x_norm[0] = coords_x_norm[0]\n",
    "        \n",
    "    if type(base_cmap) == str:\n",
    "        cmap = trimesh.visual.color.interpolate(coords_interpolated, base_cmap)\n",
    "    else:\n",
    "        cmap = interpolate_colors(coords_interpolated, base_cmap)\n",
    "        \n",
    "    cmap2 = cmap[p2p].clip(0, 255)\n",
    "\n",
    "    ##################################################\n",
    "    # add the meshes\n",
    "    ################################################\n",
    "\n",
    "    # 1\n",
    "    mesh1 = trimesh.Trimesh(vertices=verts_x, faces=faces_x, process=False, validate=False)\n",
    "    mesh1.visual.vertex_colors = cmap[:len(mesh1.vertices)].clip(0, 255)\n",
    "    \n",
    "    # cmap1_faces = trimesh.visual.color.vertex_to_face_color(cmap, mesh1.faces)\n",
    "    # mesh1.visual.face_colors = cmap1_faces.clip(0, 255).astype(np.uint8)\n",
    "      \n",
    "    # 2\n",
    "    mesh2 = trimesh.Trimesh(vertices=verts_y, faces=faces_y, process=False, validate=False)\n",
    "    mesh2.visual.vertex_colors = cmap2[:len(mesh2.vertices)]\n",
    "    \n",
    "    # cmap2_faces = trimesh.visual.color.vertex_to_face_color(cmap2, mesh2.faces)\n",
    "    # mesh2.visual.face_colors = cmap2_faces.clip(0, 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    trimesh.repair.fix_inversion(mesh1)\n",
    "    trimesh.repair.fix_inversion(mesh2)\n",
    "    \n",
    "    return mesh1, mesh2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 153\n",
    "# 154\n",
    "# 164\n",
    "# 170\n",
    "# 171\n",
    "# 181\n",
    "\n",
    "\n",
    "indx = 280\n",
    "\n",
    "data_i = pair_dataset[indx]\n",
    "p2p_i = p2p_saved[indx]\n",
    "p2p_pairzo = torch.tensor(p2p_i['p2p_median_pairzo'])\n",
    "\n",
    "print(p2p_i['geo_err_median_pairzo'])\n",
    "\n",
    "scene.geometry.clear()\n",
    "\n",
    "mesh1, mesh2 = get_colored_meshes( \n",
    "    data_i['first']['verts'], data_i['first']['faces'],\n",
    "    data_i['second']['verts'], data_i['second']['faces'],\n",
    "    p2p_pairzo,\n",
    "    axes_color_gradient=[0, 1],\n",
    "    base_cmap=cmap,\n",
    "    dataset_name=dataset_name\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# scene.add_geometry(mesh1)\n",
    "mesh2.apply_transform(trimesh.transformations.translation_matrix([1, 0, 0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scene.add_geometry(mesh2)\n",
    "\n",
    "scene.set_camera()\n",
    "scene.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# png1 = render_mesh(scene, mesh1,\n",
    "#                    f\"/home/s94zalek_hpc/shape_matching/notebooks/rebuttal/smal_qualitative/{indx}_1.png\")\n",
    "png2 = render_mesh(scene, mesh2, \n",
    "                   f\"/home/s94zalek_hpc/shape_matching/notebooks/rebuttal/smal_qualitative/{indx}_2_1.png\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, combination in enumerate(pair_dataset.combinations):\n",
    "    print(f'{i}: {single_dataset.off_files[combination[0]].split(\"/\")[-1].split(\".\")[0]} - {single_dataset.off_files[combination[1]].split(\"/\")[-1].split(\".\")[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
